{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84b4f2f1-2832-4cf8-be45-39c5003f8abf",
   "metadata": {},
   "source": [
    "### read data and calc returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b5150f59-564b-4600-8b72-8764a2b54fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv('../../bbgfactor/rty_2014.csv', parse_dates = True).set_index(['ID','DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "081434fc-a252-41d9-bc42-53a8fc780834",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df.index.duplicated()].reset_index() # causes multiindex issues later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ffedea8b-400e-4798-8f61-0b788dffe697",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset = ['close'])\n",
    "if 'Unnamed: 0' in df.columns:\n",
    "    df = df.drop(columns = ['Unnamed: 0'])\n",
    "\n",
    "df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "df = df.sort_values(['ID', 'DATE'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b9c9c246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>DATE</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>market_cap</th>\n",
       "      <th>bid</th>\n",
       "      <th>ask</th>\n",
       "      <th>baspd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3529456</th>\n",
       "      <td>2551003D US Equity</td>\n",
       "      <td>2019-03-29</td>\n",
       "      <td>29.00</td>\n",
       "      <td>29.95</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>29.95</td>\n",
       "      <td>61185.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.98</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.131854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3529459</th>\n",
       "      <td>2551003D US Equity</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>31.00</td>\n",
       "      <td>31.13</td>\n",
       "      <td>30.5438</td>\n",
       "      <td>30.98</td>\n",
       "      <td>222568.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.98</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.239853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3529460</th>\n",
       "      <td>2551003D US Equity</td>\n",
       "      <td>2019-04-02</td>\n",
       "      <td>31.00</td>\n",
       "      <td>31.50</td>\n",
       "      <td>30.6100</td>\n",
       "      <td>31.00</td>\n",
       "      <td>40901.0</td>\n",
       "      <td>1.273198e+09</td>\n",
       "      <td>30.85</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.339595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3529461</th>\n",
       "      <td>2551003D US Equity</td>\n",
       "      <td>2019-04-03</td>\n",
       "      <td>31.00</td>\n",
       "      <td>31.00</td>\n",
       "      <td>29.9000</td>\n",
       "      <td>31.00</td>\n",
       "      <td>28411.0</td>\n",
       "      <td>1.273198e+09</td>\n",
       "      <td>30.99</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.398489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3529462</th>\n",
       "      <td>2551003D US Equity</td>\n",
       "      <td>2019-04-04</td>\n",
       "      <td>31.14</td>\n",
       "      <td>31.23</td>\n",
       "      <td>30.9700</td>\n",
       "      <td>31.00</td>\n",
       "      <td>369391.0</td>\n",
       "      <td>1.273198e+09</td>\n",
       "      <td>30.99</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.196222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         ID       DATE   open   high      low  close  \\\n",
       "3529456  2551003D US Equity 2019-03-29  29.00  29.95  29.0000  29.95   \n",
       "3529459  2551003D US Equity 2019-04-01  31.00  31.13  30.5438  30.98   \n",
       "3529460  2551003D US Equity 2019-04-02  31.00  31.50  30.6100  31.00   \n",
       "3529461  2551003D US Equity 2019-04-03  31.00  31.00  29.9000  31.00   \n",
       "3529462  2551003D US Equity 2019-04-04  31.14  31.23  30.9700  31.00   \n",
       "\n",
       "           volume    market_cap    bid   ask     baspd  \n",
       "3529456   61185.0           NaN  29.98  30.1  0.131854  \n",
       "3529459  222568.0           NaN  30.98  31.0  0.239853  \n",
       "3529460   40901.0  1.273198e+09  30.85  31.0  0.339595  \n",
       "3529461   28411.0  1.273198e+09  30.99  31.0  0.398489  \n",
       "3529462  369391.0  1.273198e+09  30.99  31.0  0.196222  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "33624986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read SPX data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "724bada0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spxdf = pd.read_csv('../../bbgfactor/idx.csv', parse_dates = True).set_index(['ID','DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c3b57e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spxdf = spxdf[~spxdf.index.duplicated()].reset_index() # causes multiindex issues later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "57b2b2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "spxdf = spxdf.dropna(subset = ['close'])\n",
    "\n",
    "if 'Unnamed: 0' in spxdf.columns:\n",
    "    spxdf = spxdf.drop(columns = ['Unnamed: 0'])\n",
    "\n",
    "spxdf['DATE'] = pd.to_datetime(spxdf['DATE'])\n",
    "spxdf = spxdf.sort_values('DATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d20b5632",
   "metadata": {},
   "outputs": [],
   "source": [
    "spxdf = spxdf.query('ID == \"SPX Index\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6ee7cb-0972-48f5-a1d3-a251a7d371c6",
   "metadata": {},
   "source": [
    "### functions - ret calc and makeready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "92394532",
   "metadata": {},
   "outputs": [],
   "source": [
    "days = 63"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8f203aa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>DATE</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SPX Index</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>1213.55</td>\n",
       "      <td>1217.33</td>\n",
       "      <td>1211.65</td>\n",
       "      <td>1211.92</td>\n",
       "      <td>6.754980e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SPX Index</td>\n",
       "      <td>2005-01-03</td>\n",
       "      <td>1211.92</td>\n",
       "      <td>1217.90</td>\n",
       "      <td>1200.30</td>\n",
       "      <td>1202.08</td>\n",
       "      <td>1.331432e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SPX Index</td>\n",
       "      <td>2005-01-04</td>\n",
       "      <td>1202.08</td>\n",
       "      <td>1205.84</td>\n",
       "      <td>1185.39</td>\n",
       "      <td>1188.05</td>\n",
       "      <td>1.549158e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SPX Index</td>\n",
       "      <td>2005-01-05</td>\n",
       "      <td>1188.05</td>\n",
       "      <td>1192.75</td>\n",
       "      <td>1183.72</td>\n",
       "      <td>1183.74</td>\n",
       "      <td>1.425108e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SPX Index</td>\n",
       "      <td>2005-01-06</td>\n",
       "      <td>1183.74</td>\n",
       "      <td>1191.63</td>\n",
       "      <td>1183.23</td>\n",
       "      <td>1187.89</td>\n",
       "      <td>1.323134e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65787</th>\n",
       "      <td>SPX Index</td>\n",
       "      <td>2025-02-03</td>\n",
       "      <td>5969.65</td>\n",
       "      <td>6022.13</td>\n",
       "      <td>5923.93</td>\n",
       "      <td>5994.57</td>\n",
       "      <td>8.812059e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65788</th>\n",
       "      <td>SPX Index</td>\n",
       "      <td>2025-02-04</td>\n",
       "      <td>5998.14</td>\n",
       "      <td>6042.48</td>\n",
       "      <td>5990.87</td>\n",
       "      <td>6037.88</td>\n",
       "      <td>8.242833e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65789</th>\n",
       "      <td>SPX Index</td>\n",
       "      <td>2025-02-05</td>\n",
       "      <td>6020.45</td>\n",
       "      <td>6062.86</td>\n",
       "      <td>6007.06</td>\n",
       "      <td>6061.48</td>\n",
       "      <td>8.615793e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65790</th>\n",
       "      <td>SPX Index</td>\n",
       "      <td>2025-02-06</td>\n",
       "      <td>6072.22</td>\n",
       "      <td>6084.03</td>\n",
       "      <td>6046.83</td>\n",
       "      <td>6083.57</td>\n",
       "      <td>8.158219e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65791</th>\n",
       "      <td>SPX Index</td>\n",
       "      <td>2025-02-07</td>\n",
       "      <td>6083.13</td>\n",
       "      <td>6101.28</td>\n",
       "      <td>6019.96</td>\n",
       "      <td>6025.99</td>\n",
       "      <td>7.440741e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5059 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID       DATE     open     high      low    close        volume\n",
       "0      SPX Index 2004-12-31  1213.55  1217.33  1211.65  1211.92  6.754980e+08\n",
       "3      SPX Index 2005-01-03  1211.92  1217.90  1200.30  1202.08  1.331432e+09\n",
       "4      SPX Index 2005-01-04  1202.08  1205.84  1185.39  1188.05  1.549158e+09\n",
       "5      SPX Index 2005-01-05  1188.05  1192.75  1183.72  1183.74  1.425108e+09\n",
       "6      SPX Index 2005-01-06  1183.74  1191.63  1183.23  1187.89  1.323134e+09\n",
       "...          ...        ...      ...      ...      ...      ...           ...\n",
       "65787  SPX Index 2025-02-03  5969.65  6022.13  5923.93  5994.57  8.812059e+08\n",
       "65788  SPX Index 2025-02-04  5998.14  6042.48  5990.87  6037.88  8.242833e+08\n",
       "65789  SPX Index 2025-02-05  6020.45  6062.86  6007.06  6061.48  8.615793e+08\n",
       "65790  SPX Index 2025-02-06  6072.22  6084.03  6046.83  6083.57  8.158219e+08\n",
       "65791  SPX Index 2025-02-07  6083.13  6101.28  6019.96  6025.99  7.440741e+08\n",
       "\n",
       "[5059 rows x 7 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spxdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e3e50830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.False_"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df[['ID','DATE']].duplicated().any()\n",
    "\n",
    "spxdf[['ID','DATE']].duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0f7d1942",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(spxdf[['DATE','close']].rename(columns ={'close':'spx_close'}), on = 'DATE', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f9409d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['forward_return'] = (df.groupby('ID')['close']\n",
    "                          .shift(-days) / df['close'] - 1)\n",
    "\n",
    "df['spx_forward_return'] = (df.groupby('ID')['spx_close']\n",
    "                          .shift(-days) / df['spx_close'] - 1)\n",
    "\n",
    "df['relative_return'] = (\n",
    "        df['forward_return'] - df['spx_forward_return']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "96829952-4a5b-4de6-87bb-943fe9f14e7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_returns(df):\n",
    "    \"\"\"Helper function to calculate returns and excess returns\"\"\"\n",
    "    df = df.copy()\n",
    "    df['stock_return'] = df.groupby('ID')['close'].pct_change()\n",
    "    df['spy_return'] = df.groupby('ID')['spx_close'].pct_change()\n",
    "    df['stock_excess_return'] = df['stock_return'] - df['spy_return']\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a72fe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01dfed4a-6c12-4b5a-bd76-a7108179e09f",
   "metadata": {},
   "source": [
    "### functions - rolling reg / var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "805835de-d3a1-4cfa-85e8-fa525111f53e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def rolling_residual_variance(df, window_size, dependent_var, independent_vars):\n",
    "    \"\"\"\n",
    "    Performs rolling regression in parallel using joblib.\n",
    "\n",
    "    Args:\n",
    "        df: Pandas DataFrame containing the data.\n",
    "        window_size: Size of the rolling window.\n",
    "        dependent_var: Name of the dependent variable column.\n",
    "        independent_vars: List of names of independent variable columns.\n",
    "\n",
    "    Returns:\n",
    "        Pandas DataFrame with the regression coefficients for each window.\n",
    "        Returns None if there are issues.\n",
    "    \"\"\"\n",
    "\n",
    "    n_rows = len(df)\n",
    "    results = []\n",
    "\n",
    "    def _regress_window(i):\n",
    "        if i < window_size -1:\n",
    "            return None # Handle edge cases at beginning of dataframe\n",
    "        window_data = df.iloc[i - window_size + 1:i + 1]\n",
    "\n",
    "        X = window_data[independent_vars].values\n",
    "        y = window_data[dependent_var].values.reshape(-1,1) # Reshape y for sklearn\n",
    "\n",
    "        if len(window_data) < window_size or np.any(np.isnan(X)) or np.any(np.isnan(y)):\n",
    "            return None  # Handle cases where the window is incomplete or contains NaNs.\n",
    "        \n",
    "        model = LinearRegression()\n",
    "        model.fit(X, y)\n",
    "        y_pred = model.predict(X)\n",
    "\n",
    "        # Step 3: Calculate the residuals\n",
    "        residuals = y - y_pred\n",
    "\n",
    "        # Step 4: Compute the residual variance\n",
    "        residual_variance = np.var(residuals, ddof=1) \n",
    "\n",
    "        return {'index': df.index[i], 'residual_variance': residual_variance} # Include index for proper merging\n",
    "\n",
    "\n",
    "    results = Parallel(n_jobs=-1)(delayed(_regress_window)(i) for i in range(n_rows))\n",
    "    \n",
    "    \n",
    "\n",
    "    # Filter out None results (from edge cases or NaN windows)\n",
    "    valid_results = [r for r in results if r is not None]\n",
    "\n",
    "    if not valid_results: # Check if all results are invalid\n",
    "        return None\n",
    "\n",
    "    results_df = pd.DataFrame(valid_results)#.set_index('index')\n",
    "    \n",
    "    # Handle multiindex\n",
    "    if isinstance(results_df['index'].iloc[0], tuple):\n",
    "        results_df[list(df.index.names)] = results_df['index'].apply(pd.Series)\n",
    "        results_df = results_df.drop(columns='index').set_index(list(df.index.names))\n",
    "    else:\n",
    "        results_df = results_df.set_index('index')\n",
    "        \n",
    "    return results_df\n",
    "\n",
    "def rolling_regression(df, window_size, dependent_var, independent_vars, reg_type='OLS', alpha=1.0):\n",
    "    \"\"\"\n",
    "    Performs rolling regression in parallel using joblib, with options for OLS, Ridge, and Lasso.\n",
    "    Returns np.nan for coefficients when X or y contains NaN values.\n",
    "\n",
    "    Args:\n",
    "        df: Pandas DataFrame containing the data.\n",
    "        window_size: Size of the rolling window.\n",
    "        dependent_var: Name of the dependent variable column.\n",
    "        independent_vars: List of names of independent variable columns.\n",
    "        reg_type: Type of regression to perform ('OLS', 'Ridge', 'Lasso'). Default is 'OLS'.\n",
    "        alpha: Regularization strength for Ridge and Lasso. Default is 1.0.\n",
    "\n",
    "    Returns:\n",
    "        Pandas DataFrame with the regression coefficients for each window, indexed by the original DataFrame's index.\n",
    "        Returns None if there are issues.\n",
    "    \"\"\"\n",
    "\n",
    "    n_rows = len(df)\n",
    "    results = []\n",
    "\n",
    "    def _regress_window(i):\n",
    "        if i < window_size - 1:\n",
    "            return {'index': df.index[i],\n",
    "                   'intercept': np.nan,\n",
    "                   **dict(zip(independent_vars, [np.nan] * len(independent_vars)))}\n",
    "\n",
    "        window_data = df.iloc[i - window_size + 1:i + 1]\n",
    "\n",
    "        X = window_data[independent_vars].values\n",
    "        y = window_data[dependent_var].values.reshape(-1,1)\n",
    "\n",
    "        # Return NaN coefficients if window contains NaN or is incomplete\n",
    "        if len(window_data) < window_size or np.any(np.isnan(X)) or np.any(np.isnan(y)):\n",
    "            return {'index': df.index[i],\n",
    "                   'intercept': np.nan,\n",
    "                   **dict(zip(independent_vars, [np.nan] * len(independent_vars)))}\n",
    "\n",
    "        if reg_type.upper() == 'OLS':\n",
    "            model = LinearRegression()\n",
    "        elif reg_type.upper() == 'RIDGE':\n",
    "            model = Ridge(alpha=alpha)\n",
    "        elif reg_type.upper() == 'LASSO':\n",
    "            model = Lasso(alpha=alpha)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid reg_type. Choose 'OLS', 'Ridge', or 'Lasso'.\")\n",
    "\n",
    "        model.fit(X, y)\n",
    "        coefs = model.coef_.flatten()\n",
    "        intercept = model.intercept_\n",
    "\n",
    "        return {'index': df.index[i], 'intercept': intercept, **dict(zip(independent_vars, coefs))}\n",
    "\n",
    "    results = Parallel(n_jobs=-1)(delayed(_regress_window)(i) for i in range(n_rows))\n",
    "\n",
    "    # All results should be valid now since we're returning NaN instead of None\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # Handle multiindex\n",
    "    if isinstance(results_df['index'].iloc[0], tuple):\n",
    "        results_df[list(df.index.names)] = results_df['index'].apply(pd.Series)\n",
    "        results_df = results_df.drop(columns='index').set_index(list(df.index.names))\n",
    "    else:\n",
    "        results_df = results_df.set_index('index')\n",
    "\n",
    "    return results_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2033c2a9-5a5f-453c-8db9-f4b21374fd76",
   "metadata": {},
   "source": [
    "### calculate metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "07a947e8-2cc8-442a-89da-24bffc9bb178",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sw/kl2bvz9d5275zz0p278kz9nc0000gn/T/ipykernel_96661/207521062.py:5: FutureWarning: The default fill_method='ffill' in SeriesGroupBy.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  df['spy_return'] = df.groupby('ID')['spx_close'].pct_change()\n"
     ]
    }
   ],
   "source": [
    "mdf = calculate_returns(df).set_index(['ID','DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701e2fa4-edb6-4bd6-b7bd-bbe3c583502a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76a5d9b1-81b2-4a39-be75-7fe982a10267",
   "metadata": {},
   "source": [
    "### technical factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0214a6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_period = 252\n",
    "vol_period = 63"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81939a38-1777-49ea-a478-5a95ae2f5269",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf['beta'] = mdf\\\n",
    ".groupby('ID', group_keys = False).apply(lambda x: rolling_regression(x, window_size =  beta_period, dependent_var = 'stock_return', independent_vars = ['spy_return']))\\\n",
    ".drop(columns = 'intercept')\\\n",
    ".rename(columns = {'spy_return':'beta'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6900888e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "mdf['volatility'] = mdf.groupby('ID',group_keys = False)['stock_return'].rolling(vol_period).std().mul(np.sqrt(252)).reset_index(level = 0, drop = True).rename('volatility')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7f850f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mdf['avg_volm_to_cap'] = mdf.groupby('ID', group_keys = False).apply(lambda x: x['volume'].rolling(vol_period).mean()/(x['market_cap']/1000000)).rename('avg_volm_to_cap')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f489239",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "mdf['volume_trend'] = mdf.groupby('ID', group_keys = False).apply(lambda x: rolling_regression(x.assign(trend = lambda x:np.arange(len(x))), window_size = vol_period , dependent_var = 'volume', independent_vars = ['trend'])).rename(columns = {'trend':'volume_trend'}).drop(columns = 'intercept')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c246519",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "mdf['residual_variance'] = mdf.groupby('ID', group_keys = False).apply(lambda x: rolling_residual_variance(x, window_size = vol_period , dependent_var = 'stock_return', independent_vars = ['spy_return']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60740c26-8a26-449a-a2ea-3910aebe749b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compound_returns(returns):\n",
    "    return (1 + returns).prod() - 1\n",
    "\n",
    "# List of rolling periods to calculate\n",
    "periods = [1, 2, 3, 6, 12]*21\n",
    "\n",
    "# Calculate rolling compounded returns for each period\n",
    "for period in periods:\n",
    "    # Stock returns\n",
    "    mdf[f'stock_return_{period}m'] = mdf.groupby('ID')['stock_return'].rolling(\n",
    "        window=period, min_periods=period\n",
    "    ).apply(compound_returns).reset_index(level = 0, drop = True).values\n",
    "\n",
    "    # SPY returns\n",
    "    mdf[f'spy_return_{period}m'] = mdf.groupby('ID')['spy_return'].rolling(\n",
    "        window=period, min_periods=period\n",
    "    ).apply(compound_returns).reset_index(level = 0, drop = True).values\n",
    "\n",
    "    # Calculate excess returns (stock - spy)\n",
    "    mdf[f'rs_{period}m'] = mdf[f'stock_return_{period}m'] - mdf[f'spy_return_{period}m']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd43d574-05a4-4400-b0c3-325e800698ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf['3mrs_3mago'] = mdf.groupby('ID')['rs_3m'].shift(3)\n",
    "mdf['3mrs_6mago'] = mdf.groupby('ID')['rs_3m'].shift(6)\n",
    "mdf['3mrs_9mago'] = mdf.groupby('ID')['rs_3m'].shift(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7d3c92-c1e5-4eaa-b948-0fa50d85b630",
   "metadata": {},
   "source": [
    "### value factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7984e12f-db95-44b0-8c8a-6ddde4035c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# earnings to price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1607a63-3a55-4f0f-b9f1-c6444b94c219",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf['eps_to_price'] = mdf.groupby('ID').apply(lambda x: x['eps']/x['px_last_splits']).reset_index(0, drop = True)\n",
    "\n",
    "\n",
    "mdf['eps_to_price_trend']= mdf.groupby('ID', group_keys = False)\\\n",
    ".apply(lambda x: rolling_regression(x.assign(trend = lambda x:np.arange(len(x))), window_size = 24 , dependent_var = 'eps_to_price', independent_vars = ['trend']))\\\n",
    ".rename(columns = {'trend':'eps_to_price_trend'}).drop(columns = 'intercept')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb0b4cb-45f7-4b74-87b7-04e6d867cf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sales to price "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb8480d-892a-4371-be6d-086c4dfb8da2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63501266-5c3c-42c3-afce-6638cdf97e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf['sales_to_price'] = mdf.groupby('ID').apply(lambda x: x['sales']/x['px_last_splits']).reset_index(0, drop = True)\n",
    "\n",
    "\n",
    "mdf['sales_to_price_trend']= mdf.groupby('ID', group_keys = False)\\\n",
    ".apply(lambda x: rolling_regression(x.assign(trend = lambda x:np.arange(len(x))), window_size = 24 , dependent_var = 'sales_to_price', independent_vars = ['trend']))\\\n",
    ".rename(columns = {'trend':'sales_to_price_trend'}).drop(columns = 'intercept')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec6717c-6556-4bb5-87a7-6156c7d4668b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cash to price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a77f91f-f957-4121-baa7-1364e3913ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf['fcf_calc'] = mdf['cfo_ltm_a'] + mdf['capex'] + mdf['dvd'] \n",
    "\n",
    "mdf['cash_to_price'] = mdf['fcf_calc'] / mdf['px_last_splits']\n",
    "\n",
    "mdf['cash_to_price_trend']= mdf.groupby('ID', group_keys = False)\\\n",
    ".apply(lambda x: rolling_regression(x.assign(trend = lambda x:np.arange(len(x))), window_size = 24 , dependent_var = 'cash_to_price', independent_vars = ['trend']))\\\n",
    ".rename(columns = {'trend':'cash_to_price_trend'}).drop(columns = 'intercept')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76ffa15-18ad-46be-8ad7-c90220cae30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividend to price "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2898b4-054b-4d0f-90b6-586d2487860e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf['div_to_price'] = np.abs(mdf['dvd']) / mdf['px_last_splits']\n",
    "\n",
    "mdf['div_to_price_trend']= mdf.groupby('ID', group_keys = False)\\\n",
    ".apply(lambda x: rolling_regression(x.assign(trend = lambda x:np.arange(len(x))), window_size = 24 , dependent_var = 'div_to_price', independent_vars = ['trend']))\\\n",
    ".rename(columns = {'trend':'div_to_price_trend'}).drop(columns = 'intercept')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2354adda-5784-4d19-8d50-fba04d4695b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# book to price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bf8cca-9026-4ee1-9f50-91efcef1d7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf['book_to_price'] = mdf['book_value'] / mdf['cur_mkt_cap']\n",
    "\n",
    "mdf['book_to_price_trend']= mdf.groupby('ID', group_keys = False)\\\n",
    ".apply(lambda x: rolling_regression(x.assign(trend = lambda x:np.arange(len(x))), window_size = 24 , dependent_var = 'book_to_price', independent_vars = ['trend']))\\\n",
    ".rename(columns = {'trend':'book_to_price_trend'}).drop(columns = 'intercept')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d454fcd6-f6c4-4b34-8c84-b304902be080",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9ff45db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf = mdf[['forward_return',\n",
    "           'stock_excess_return',\n",
    "           'market_cap',\n",
    "           'avg_volm_to_cap',\n",
    "             'volume',\n",
    "             'volatility',\n",
    "             ]]\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fefe581-520e-4ac1-8bd5-a0e255ed5239",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf = mdf[['stock_return',\n",
    "           'cur_mkt_cap',\n",
    "           'px_last_splits',\n",
    "           'beta',\n",
    "             'volatility',\n",
    "             'avg_volm_to_cap',\n",
    "             'volume_trend',\n",
    "             'residual_variance',\n",
    "             'stock_return_1m',\n",
    "             'rs_1m',\n",
    "             'stock_return_2m',\n",
    "\n",
    "             'rs_2m',\n",
    "             'stock_return_3m',\n",
    "\n",
    "             'rs_3m',\n",
    "             'stock_return_6m',\n",
    "\n",
    "             'rs_6m',\n",
    "             'stock_return_12m',\n",
    "\n",
    "             'rs_12m',\n",
    "             '3mrs_3mago',\n",
    "             '3mrs_6mago',\n",
    "             '3mrs_9mago',\n",
    "             'eps_to_price',\n",
    "             'eps_to_price_trend',\n",
    "             'sales_to_price',\n",
    "             'sales_to_price_trend',\n",
    "             'fcf_calc',\n",
    "             'cash_to_price',\n",
    "             'cash_to_price_trend',\n",
    "             'div_to_price',\n",
    "             'div_to_price_trend',\n",
    "             'book_to_price',\n",
    "             'book_to_price_trend']]\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1240b928-9da7-4476-abd4-ff68c33c928d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcols = fdf.columns.to_list()\n",
    "fcols.remove('forward_return')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9a2a7a63-c260-4f25-bdd1-a6ee8583bbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf = fdf.groupby('DATE').transform(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8a5663d4-3835-4568-a76b-c85dbcf97f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.mstats import winsorize\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# df[numcols] = df[numcols].groupby('ITERATION_DATE').transform(lambda x: winsorize(x, limits = (0.01,0.01)))\n",
    "fdf[fcols] = fdf[fcols].groupby('DATE').transform(lambda x: zscore(x).clip(-3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fa33b5a6-fe0a-4ab1-9854-31c214a8a071",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# now we are calculating forward returns, so if standing on Dec 1, its 3m forward returns and Dec 1 features, so we are good, nothign to shift \n",
    "fdf = fdf.dropna(subset = ['forward_return'])\n",
    "# fdf[fcols] = fdf.groupby(level = 'ID')[fcols].shift(days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a674e2cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "82c96694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>forward_return</th>\n",
       "      <th>stock_excess_return</th>\n",
       "      <th>market_cap</th>\n",
       "      <th>avg_volm_to_cap</th>\n",
       "      <th>volume</th>\n",
       "      <th>volatility</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAMI UN Equity</th>\n",
       "      <td>0.284644</td>\n",
       "      <td>0.194273</td>\n",
       "      <td>-0.030936</td>\n",
       "      <td>-0.106074</td>\n",
       "      <td>0.309433</td>\n",
       "      <td>-0.418957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAOI UQ Equity</th>\n",
       "      <td>-0.213869</td>\n",
       "      <td>0.523236</td>\n",
       "      <td>-0.715685</td>\n",
       "      <td>1.000699</td>\n",
       "      <td>0.408269</td>\n",
       "      <td>0.613026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAT UN Equity</th>\n",
       "      <td>0.155091</td>\n",
       "      <td>-0.172455</td>\n",
       "      <td>0.596940</td>\n",
       "      <td>-0.194819</td>\n",
       "      <td>-0.190088</td>\n",
       "      <td>-0.918115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABCB UN Equity</th>\n",
       "      <td>0.109143</td>\n",
       "      <td>-0.097693</td>\n",
       "      <td>0.270851</td>\n",
       "      <td>-0.240706</td>\n",
       "      <td>-0.610050</td>\n",
       "      <td>-0.354256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABG UN Equity</th>\n",
       "      <td>0.053405</td>\n",
       "      <td>0.172590</td>\n",
       "      <td>0.110077</td>\n",
       "      <td>-0.170802</td>\n",
       "      <td>-0.500345</td>\n",
       "      <td>-0.449576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                forward_return  stock_excess_return  market_cap  \\\n",
       "ID                                                                \n",
       "AAMI UN Equity        0.284644             0.194273   -0.030936   \n",
       "AAOI UQ Equity       -0.213869             0.523236   -0.715685   \n",
       "AAT UN Equity         0.155091            -0.172455    0.596940   \n",
       "ABCB UN Equity        0.109143            -0.097693    0.270851   \n",
       "ABG UN Equity         0.053405             0.172590    0.110077   \n",
       "\n",
       "                avg_volm_to_cap    volume  volatility  \n",
       "ID                                                     \n",
       "AAMI UN Equity        -0.106074  0.309433   -0.418957  \n",
       "AAOI UQ Equity         1.000699  0.408269    0.613026  \n",
       "AAT UN Equity         -0.194819 -0.190088   -0.918115  \n",
       "ABCB UN Equity        -0.240706 -0.610050   -0.354256  \n",
       "ABG UN Equity         -0.170802 -0.500345   -0.449576  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdf.xs('2018-12-31', level = 'DATE').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056eb4fc-2d77-472f-b96b-17dae19f65ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = fdf\\\n",
    ".groupby('DATE', group_keys = False).apply(lambda x: rolling_regression(x, window_size = 24 , dependent_var = 'stock_return', independent_vars = fcols))\\\n",
    ".drop(columns = 'intercept')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ab9cce-1a38-4da7-801f-edeb81f7c131",
   "metadata": {},
   "outputs": [],
   "source": [
    "betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ee8d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is ignoring a lot of the features, but need this for now to proceed with just model fitting \n",
    "# goal is daily data, \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b29b4750-cdb5-467e-b490-a51d8edb1c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf.to_csv('../../bbgfactor/rty_2014_smallfeatures.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26392c75-575e-45d9-b871-7a40fb15d996",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b26dec5b-83cb-4e31-841d-56102e2391c8",
   "metadata": {},
   "source": [
    "### testing dataframe "
   ]
  },
  {
   "cell_type": "raw",
   "id": "99eef62f-4fd3-4445-9b61-3447367812a2",
   "metadata": {},
   "source": [
    "np.random.seed(42)\n",
    "n_rows = 100\n",
    "data = {\n",
    "    'ID': np.random.choice(['A', 'B', 'C'], n_rows),\n",
    "    'DATE': pd.to_datetime('2023-01-01') + pd.to_timedelta(np.arange(n_rows), unit='D'),\n",
    "    'A': np.random.rand(n_rows),\n",
    "    'B': np.random.rand(n_rows),\n",
    "    'C': np.random.rand(n_rows),\n",
    "    'Y': 2 * np.random.rand(n_rows) + 0.5\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df = df.set_index('DATE') # Set DATE as index for proper rolling\n",
    "\n",
    "window_size = 20\n",
    "dependent_var = 'Y'\n",
    "independent_vars = ['A', 'B', 'C']\n",
    "\n",
    "def apply_rolling_regression(group):\n",
    "    \"\"\"Applies rolling regression to a group of data.\"\"\"\n",
    "    return rolling_regression(group, window_size, dependent_var, independent_vars)\n",
    "\n",
    "results_grouped = df.groupby('ID').apply(apply_rolling_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a10061-79fd-4140-aca9-94380488f75b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
